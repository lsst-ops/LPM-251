\section{Cost Impacts}\label{sec:costs}

{\color{red} Wil } \newline

As previously mentioned, standing up and maintaining multiple iDACs comes at a significant cost impact to both the LSST Project and the partner institutions. Minimizing these costs -- or at least maximizing the amount of science they enable -- should be at the forefront of all considerations concerning partner iDACs, such as the following propositions.

\subsection{Maximizing Profits with Science-Driven iDACs}
There are two main cost impacts of iDACs being set up outside of the US and Chilean DACs: the positive impact is that some computational load may be taken off of these existing DACs, but the negative impact is the level of support required from the LSST Project in order to get them set up and running. This negative impact could be mitigated by ensuring that science productivity is maximized as a result of this extended effort. One way to do this might be to associate specific areas of science to a given iDAC, and encourage users working in that field to use that iDAC. This could create a customer base for the iDAC, bring together like-minded experts, and effectively distribute the computing load across a network of iDACs. This might also enhance internal funding arguments for investment resources by arguing for synergies with local science goals and attracting international users and official endorsement.

%%%MLG: retained as a comment.
% In HEP experiments such as  BABAR various physics analysis groups (science collaborations in LSST ) were assigned to specific international centers as their primary computing and analysis facility, thereby distributing the computing load around the "network". People naturally tend to use the facility with available resources and cycles anyway of course. National groups received credit against their normal "operating common fund" contributions (equivalent to part of the LSST operations cost) based on their local computing contribution, and service to the full collaboration (equivalent to the full LSST data rights community). We have no such system in place for LSST though.

\subsection{Data Transfer}
Even with good networks the data transfer will not be trivial, and could be quite expensive. LSST is not currently set up to distribute data to multiple sites, i.e., there is no form of peer-to-peer sharing. The bandwidth at NCSA is adequate for receiving data and delivering {\tt Alerts} to brokers during the night; perhaps some day time bandwidth could be used to transfer data to iDACs. A full data release of images and catalogs does not have to transferred within a given day; if the correct agreements are in place with an iDAC, a full release could be transferred slowly as it is produced, and then made available to the iDACs users in whole on the official release day.
\input{xfercost}

\subsection{Compute {\it vs.} Storage Resources}
Data storage is a large cost to iDACs, and could be considered as an overhead relative to the amount of computational resources an iDAC can offer. If an iDAC is set up without a large compute capacity, the facility might be less useful to the science community than e.g., augmenting an existing DAC or iDAC to have more computational resources. It is conceivable that a partner institution may prefer to spend their money increasing the computational quotas available for a given collaboration or set of PIs, and it would be scientifically beneficial if this was possible at all DAC and iDACs. The notion of standard compute quotas and resource allocation committees to adjudicate on large proposals for substantial increases to computational allocations are described in \citeds{LPM-261}. Another way to approach a solution to this issue might be to have a \emph{Cloud}-based iDAC where a user or PI could buy nodes on the provider cloud to access the holdings put there by LSST.
